{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tf_agents.environments import py_environment\n",
    "from tf_agents.environments import utils\n",
    "from tf_agents.specs import array_spec\n",
    "from tf_agents.trajectories import time_step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Define an environment class as an inheritance from PyEnvironment\n",
    "Instances from this class represent first-order delay systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyEnv(py_environment.PyEnvironment):\n",
    "    '''\n",
    "    \n",
    "    Y(s) = K/(1+T*s) * U(s)\n",
    "    \n",
    "    T * dy(t)/dt = - y(t) + K * u(t), t > 0, \n",
    "    y(0) = y_init.\n",
    "    \n",
    "    y(t+1) = (1-1/T) * y(t) + K / T * u(t), t = 1,2, ...\n",
    "    y(0) = y_init.\n",
    "    \n",
    "    x(t+1) = (1-1/T) * x(t) + K / T * u(t), t = 1,2, ...\n",
    "    x(0) = x_init, \n",
    "    y(t) = x(t).\n",
    "    \n",
    "    '''\n",
    "\n",
    "    def __init__(self, nStepSimulation = 100, T = 10, K = 1.0, discount = 0.9):\n",
    "        self._action_spec = array_spec.BoundedArraySpec(\n",
    "            shape=(), dtype=np.float32, minimum=-1, maximum=1, name='action')\n",
    "\n",
    "        self._observation_spec = array_spec.BoundedArraySpec(\n",
    "            shape=(), dtype=np.float32, minimum=-1, maximum=1, name='observation')\n",
    "\n",
    "        self._state = self.getInitialState()\n",
    "        self._episode_ended = False\n",
    "        self.time = 0\n",
    "        self.nStepSimulation = nStepSimulation\n",
    "        self.T = T\n",
    "        self.K = K\n",
    "        self.discount = discount\n",
    "    \n",
    "    def getInitialState(self):\n",
    "        return 0.\n",
    "    \n",
    "    def getObservation(self):\n",
    "        return np.array(self._state, np.float32) # (,)\n",
    "    \n",
    "    def getReward(self):\n",
    "        sv = 1.0\n",
    "        err = sv - self.getObservation()\n",
    "        return np.abs(err)\n",
    "    \n",
    "    def action_spec(self):\n",
    "        return self._action_spec\n",
    "    \n",
    "    def observation_spec(self):\n",
    "        return self._observation_spec\n",
    "\n",
    "    def _reset(self):\n",
    "        self.time = 0\n",
    "        self._state = self.getInitialState()\n",
    "        self._episode_ended = False\n",
    "        \n",
    "        return time_step.restart(self.getObservation())\n",
    "\n",
    "    def _step(self, action):\n",
    "        \n",
    "        if self._episode_ended:\n",
    "            # The last action ended the episode. Ignore the current action and start\n",
    "            # a new episode.\n",
    "            return self.reset()\n",
    "        \n",
    "        if self.time < self.nStepSimulation:\n",
    "            \n",
    "            self._state = (1-1/self.T) * self._state + self.K/self.T * action\n",
    "            \n",
    "            self.time += 1\n",
    "            return time_step.transition(self.getObservation(), reward = self.getReward(), discount = self.discount)\n",
    "        else:\n",
    "            self._episode_ended = True\n",
    "            return time_step.termination(self.getObservation(), reward = self.getReward())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aSimpleUnitTest():\n",
    "    env = MyEnv()\n",
    "    assert isinstance(env, py_environment.PyEnvironment)\n",
    "    utils.validate_py_environment(env, episodes=5)\n",
    "\n",
    "def anotherSimpleUnitTest():\n",
    "    env = MyEnv()\n",
    "    assert isinstance(env, py_environment.PyEnvironment)\n",
    "\n",
    "    u = np.array(np.random.randn(), np.float32) # (,)\n",
    "    \n",
    "    time_step = env.reset()    \n",
    "    rewardAvg = time_step.reward    \n",
    "    while not time_step.is_last():\n",
    "        time_step = env.step(u)\n",
    "        rewardAvg = (1-1/10) * rewardAvg + 1/10 * time_step.reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aSimpleUnitTest()\n",
    "anotherSimpleUnitTest()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
