{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [tutorial#1](https://blog.tensorflow.org/2019/03/variational-autoencoders-with.html)\n",
    "    * An implementation of the VAEs by using Tensorflow Probability Layers\n",
    "* [tutorial#2](https://www.tensorflow.org/tutorials/generative/cvae)\n",
    "    * An implementation of the VAEs on the official site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import tensorflow.keras as tfk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_mode = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method definitions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createPriorDistribution(encoded_size, isBound = False):\n",
    "    tfd = tfp.distributions\n",
    "\n",
    "    if isBound:\n",
    "        p_x = tfd.Normal(loc=tf.zeros(encoded_size), scale=1)\n",
    "        p_y = tfd.TransformedDistribution(distribution=p_x, bijector = tfp.bijectors.Tanh())\n",
    "        prior = tfd.Independent(p_y, reinterpreted_batch_ndims=1)\n",
    "        return prior\n",
    "    else:\n",
    "        p_x = tfd.Normal(loc=tf.zeros(encoded_size), scale=1)\n",
    "        prior = tfd.Independent(p_x, reinterpreted_batch_ndims=1)\n",
    "        return prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if debug_mode:\n",
    "    prior = createPriorDistribution(encoded_size=16, isBound=True);\n",
    "    prior = createPriorDistribution(encoded_size=16, isBound=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createEncoder(input_shape, prior):\n",
    "    tfpl = tfp.layers\n",
    "    tfkl = tfk.layers\n",
    "    \n",
    "    encoded_size = prior.event_shape[0]\n",
    "\n",
    "    encoder = tfk.Sequential([\n",
    "        tfkl.InputLayer(input_shape=input_shape),\n",
    "        tfkl.Dense(tfpl.MultivariateNormalTriL.params_size(encoded_size), \n",
    "                   activation=None),\n",
    "        tfpl.MultivariateNormalTriL(\n",
    "            encoded_size,\n",
    "            activity_regularizer=tfpl.KLDivergenceRegularizer(prior, weight=1.0)),\n",
    "        ])\n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if debug_mode:\n",
    "    input_shape = (3,)\n",
    "    encoder = createEncoder(input_shape, prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDecoder(input_shape, prior):\n",
    "    tfpl = tfp.layers\n",
    "    tfkl = tfk.layers\n",
    "\n",
    "    encoded_size = prior.event_shape[0]\n",
    "    n = input_shape[0]\n",
    "\n",
    "    decoder = tfk.Sequential([\n",
    "        tfkl.InputLayer(input_shape=[encoded_size]) #  (encode_size)\n",
    "        , tfkl.Dense(tfpl.MultivariateNormalTriL.params_size(n), activation = None) # (encode_size) => input_shape[0] + input_shape[0]**2/2\n",
    "        , tfpl.MultivariateNormalTriL(n) # => mu: (input_shape[0],), Sigma: (input_shape[0], input_shape[0])\n",
    "        ])\n",
    "    return decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if debug_mode:\n",
    "    decoder = createDecoder(input_shape, prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTrainDataset(input_shape):\n",
    "    assert input_shape == (2,)\n",
    "    sample_size = 2**7\n",
    "    x1 = tf.random.normal(shape = (sample_size, input_shape[0])) + [-1, -1]\n",
    "    x2 = tf.random.normal(shape = (sample_size, input_shape[0])) + [1, 1]\n",
    "    x = tf.concat((x1, x2), axis=0)\n",
    "\n",
    "    batch_size = 2**5\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((x, x)).shuffle(sample_size).batch(batch_size) # generates (batch_size, *input_shape)    \n",
    "    return train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createEvalDataset(input_shape):\n",
    "    assert input_shape == (2,)\n",
    "    sample_size = 2**7\n",
    "    x1 = tf.random.normal(shape = (sample_size, input_shape[0])) - tf.ones(shape=(sample_size, input_shape[0]))\n",
    "    x2 = tf.random.normal(shape = (sample_size, input_shape[0])) + tf.ones(shape=(sample_size, input_shape[0]))\n",
    "    return x1, x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTrainDatasetForDebug(input_shape):\n",
    "    sample_size = 2**7\n",
    "    batch_size = 2**5\n",
    "    xRaw = tf.random.normal(shape=(sample_size, input_shape[0])) # (sample_size, *input_shape)\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((xRaw, xRaw)).shuffle(sample_size).batch(batch_size) # generates (batch_size, *input_shape)\n",
    "    return train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if debug_mode:\n",
    "    createTrainDataset((2,))\n",
    "    createEvalDataset((2,))\n",
    "    train_dataset = createTrainDatasetForDebug(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainVAEs(encoder, decoder, train_dataset, epochs):\n",
    "\n",
    "    vae = tfk.Model(inputs=encoder.inputs,\n",
    "                    outputs=decoder(encoder.outputs[0]))\n",
    "\n",
    "    negative_log_likelihood = lambda x, rv_x: -rv_x.log_prob(x)\n",
    "\n",
    "    vae.compile(optimizer=tf.optimizers.Adam(learning_rate=1e-3),\n",
    "                loss=negative_log_likelihood)\n",
    "\n",
    "    vae.fit(train_dataset, epochs = epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if debug_mode: \n",
    "    trainVAEs(encoder, decoder, train_dataset, epochs = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (2,)\n",
    "\n",
    "train_dataset = createTrainDataset(input_shape)\n",
    "x1, x2 = createEvalDataset(input_shape)\n",
    "\n",
    "prior = createPriorDistribution(encoded_size=2, isBound=False);\n",
    "decoder = createDecoder(input_shape, prior)\n",
    "encoder = createEncoder(input_shape, prior)\n",
    "\n",
    "trainVAEs(encoder, decoder, train_dataset, epochs = 2**8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z1 = encoder(x1).sample(sample_shape=()).numpy() # (128, 2)\n",
    "z2 = encoder(x2).sample(sample_shape=()).numpy() # (128, 2)\n",
    "\n",
    "x1hat = decoder(z1).sample().numpy()\n",
    "x2hat = decoder(z2).sample().numpy()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(z1[:,0], z1[:,1], 'ro')\n",
    "plt.plot(z2[:,0], z2[:,1], 'bo')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x1[:,0], x1[:,1], 'k+')\n",
    "plt.plot(x2[:,0], x2[:,1], 'kx')\n",
    "plt.plot(x1hat[:,0], x1hat[:,1], 'ro', markerfacecolor=\"none\")\n",
    "plt.plot(x2hat[:,0], x2hat[:,1], 'bo', markerfacecolor=\"none\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
